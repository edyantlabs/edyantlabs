# Edyant Labs
![Profile Views](https://komarev.com/ghpvc/?username=edyantlabs&color=00D4FF&style=for-the-badge)

**Open-source research for responsible AI frameworks in the real world.**

## About
Edyant Labs is an all-IITians-led open initiative dedicated to advancing next generation of AI systems. We focus on responsible AI frameworks for real-world systems. We build research-grade frameworks and benchmarks that keep AI grounded in context, consequences, and human needs.

Our work targets human-AI interaction where perception, memory, and ethics shape safe behavior in complex environments. We publish frameworks, benchmarks, and experiments so others can test, extend, and build on this work collaboratively.

### Our Vision

Today, most AI systems act as tools: they respond to inputs, optimize outputs, and leave humans to interpret consequences.

Edyant is working toward something different.

We believe AI systems must:
- Understand the humans they interact with
- Adapt behavior across age, culture, and context
- Operate with ethical constraints, not just performance goals
- Maintain continuity, memory, and identity over time
- Take ownership of actions in real-world systems

Our goal is to transition AI from **reactive tools** to **responsible agents**.

### The Four Frameworks
#### Ethics & Morals
Ethics & Morals equips AI with value-based reasoning for real-world trade-offs. It helps AI balance safety, dignity, autonomy, and efficiency and explain the values behind action choices. This is foundational to responsible AI governance.

#### Persistence & Continuity
Persistence & Continuity treats memory as lived experience in AI. It enables long-horizon memory, skill retention, and accountability across deployments, so AI improves over time without repeating the same mistakes. Continuity is essential for trust in human-AI interaction.

#### Socially Aware Interaction
Socially Aware Interaction adapts AI behavior to human diversity, context, and environment. It emphasizes adaptive communication, respectful pacing, and accessibility in real-world interaction. The goal is inclusive, humane AI that meets people where they are.

#### Sensor-Grounded Awareness
Sensor-Grounded Awareness anchors AI in multimodal signals beyond text. It enables situational awareness through data, telemetry, and contextual cues so AI acts with real-world context. This grounding is critical for safe, transparent systems.

### Why It Matters
AI operates in homes, hospitals, workplaces, and public services. Mistakes are not abstract. Responsible AI must reason about context, adapt to human needs, and remain accountable for real-world outcomes.

### Open-Source Ethos
Edyant Labs is open by design. We welcome collaboration, critical feedback, and contributions that strengthen responsible AI and human-AI interaction. Use the frameworks, test them in new environments, and share improvements back with the community.

---

<div align="center">

![HTML5](https://img.shields.io/badge/HTML5-E34F26?style=for-the-badge&logo=html5&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black)
![CSS3](https://img.shields.io/badge/CSS3-1572B6?style=for-the-badge&logo=css3&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)

</div>
<div align="center">

![Firebase](https://img.shields.io/badge/Firebase-FFCA28?style=for-the-badge&logo=firebase&logoColor=black)
![Google Cloud](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)

</div>

